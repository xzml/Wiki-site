---
title: 数据集下载和处理
toc: true
date: 2019-04-14 21:46:23
tags: [深度学习]
categories:
---

最近在考虑一个问题, 现在 PyTorch 等框架将网络训练整个流程都封装的很好, 比如数据下载, 预处理等等, 我在想如果以后遇到了非标准的数据集那该怎么办, 因此非常有必要自己将数据处理的部分从头动手做一遍, 于是有了下面的代码.

## 代码剖析

完整代码可以看下一节, 这节对其中的细节作分析.

### 下载数据并解压

```python
## progress bar of download_url
def gen_bar_updater():
    pbar = tqdm(total=None)

    def bar_update(count, block_size, total_size):
        if pbar.total is None and total_size:
            pbar.total = total_size
        ## `count` is incremental,
        progress_bytes = count * block_size
        ## `pbar.n`: current state of the bar
        pbar.update(progress_bytes - pbar.n)

    return bar_update

def download_url(url, root, filename=None):
    if not os.path.exists(root):
        os.makedirs(root)

    if not filename:
        filename = os.path.basename(url)
    fpath = os.path.join(root, filename)

    if os.path.exists(fpath):
         print('{} exists, no need downloding!'.format(filename))
    else:
        print('Downloading {} to {}'.format(url, fpath))
        urllib.request.urlretrieve(url, fpath,
                               reporthook=gen_bar_updater())
    extract_gzip(fpath, remove_finished=False)
```

使用 `urllib` 中的 `urlretrieve` 对 `url` 中的数据进行下载并保存到 `fpath` 路径, 其中 `reporthook` 参数接受一个函数对象, 该函数对象需要包含 `(count, block_size, total_size)` 三个参数, 因此该代码使用 `gen_bar_updater` 来产生该函数对象, 这样在下载数据时就会有一个进度条.

+ 在 `gen_bar_updater` 中, `count` 在每次更新都会变化, 进度条当前的位置为 `pbar.n`, 而下一步要变化到 `progress_bytes`, 因此当前更新中, 进度条需要前进 `progress_bytes - pbar.n`. 通过这个小知识, 可以了解 `tqdm` 大致是怎么运作的.
+ `if os.path.exists(fpath)` 表示, 如果数据已经下载, 那么可以不用处理, 直接去解压
+ 编写 `extract_gzip()` 函数来解压文件, 其中使用 `gzip` 包来处理 `*.gz` 文件, 使用 `tarfile` 包来处理 `*.tar.gz` 文件, 但是 `tarfile` 应该也可以处理 `*.gz` 文件… `extract_gzip` 这里就不详细介绍了. 

当将数据解压好后, 需要将数据读入内存, 最后将数据保存为大小为 `(N, C, H, W)` 的 Torch Tensor. 根据数据集是 MNIST 还是 CIFAR 需要分开处理.

## MNIST

MNIST 的网址是 <http://yann.lecun.com/exdb/mnist/>

根据网站中的介绍, MNIST 的训练数据 `train-images-idx3-ubyte` 是这样组织的:

![mnist-train-set.png](https://i.loli.net/2019/04/14/5cb340d637a93.png)

* 首先, 肯定是以二进制的形式读取 `train-images-idx3-ubyte` 的:

其中前 4 位为 magic number, 4~8 为图像数量, 8~12 为行数, 12~16 为列数, 最后剩下的位为图像自身的像素, `np.frombuffer` 可以直接解析这些二进制位, 注意其中的参数 `offset`. 此外, 为了得到图像数量等, 还使用了 `get_int`, 它可以将二进制位转换为整数, 首先将二进制编码为十六进制 `hex`, 然后转换为 10 进制. (发现好多函数自己真的不熟啊), 

* 最后通过 `torch.from_numpy` 将 numpy 数组转换为 Tensor.
* 读取 label 同理, 但是需要注意一个问题, **label 的类型是** **`LongTensor**`!!!!

```python
def get_int(b):
    return int(codecs.encode(b, 'hex'), 16)

def read_image_file(path):
    with open(path, 'rb') as f:
        data = f.read()
        assert get_int(data[:4]) == 2051
        num_images = get_int(data[4 : 8])
        num_rows = get_int(data[8 : 12])
        num_cols = get_int(data[12 : 16])
        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)
        return torch.from_numpy(parsed).view(num_images, 1, num_rows, num_cols)
```

* 最终将 `(data, labels)` pair 保存到 `mnist_train.pth` 文件中:

```python
with open(os.path.join(path, data_file), 'wb') as f:
    torch.save(dataset, f)
```

## CIFAR

CIFAR 的网址是 <https://www.cs.toronto.edu/~kriz/cifar.html>

CIFAR 解压后是一个新的目录: `cifar-10-batches-py/`, 看看官网的介绍:

![cifar10-data.png](https://i.loli.net/2019/04/14/5cb343a911712.png)

数据文件分为好几个: `data_batch_i` 以及 `test_batch`, 官网给了读取数据的代码, 我们可以利用. 读取成功后是一个字典, 虽然上面说 key 有 `data` 以及 `labels` 等, 但实际上是 `b'data'`.

这里有个问题, 由于数据分成了好几个文件, 我要将它们组合成一个大的数据矩阵, 就需要将每个文件中的数据进行 concatenate, 如何优雅的写出这部分的代码呢? 如果以后有好的思路一定要记下来, 这里使用 `list comprehension`:

```python
def unpickle(datafile):
    import pickle
    with open(datafile, 'rb') as fo:
        data_dict = pickle.load(fo, encoding='bytes')
    return data_dict

def data_batch(i, path, key='data'):
    data_dict = unpickle(os.path.join(path, 'data_batch_{}'.format(i)))
    return data_dict[key]

def prepare_dataset(...):
    ### ...
    data_array = np.concatenate(
                [data_batch(i, cifar_path, b'data') for i in range(1, 6)],
                axis=0
            )
    label_array = np.concatenate(
                [data_batch(i, cifar_path, b'labels') for i in range(1, 6)],
                axis=0
            )
    torch_data = torch.from_numpy(data_array).view(-1, 3, 32, 32)
    torch_label= torch.from_numpy(label_array).long()
	### ...
```

so easy! 最后将结果保存在 `cifar_train/test.pth` 中.



### 辅助代码

#### 查看图片

这可以显示一个 array.

```python
def show_array(array, show=False):
    array = np.array(array).transpose((1, 2, 0))
    h, w, c = array.shape
    array = array.squeeze()
    if c > 1: cmap = None
    else: cmap = 'gray'
    fig, ax = plt.subplots()
    ax.imshow(array, cmap=cmap)
    if show:
        plt.show()
```

需要注意两个问题:

* 对于灰度图, 将数组大小转换为 `(h, w, 1)` 在扔进 `imshow` 中是会报错的, 因此需要使用 `squeeze()` 去掉 `1` 这个 dimension.
* 如果是显示灰度图, `cmap` 可以设置为 `gray`

#### 查看一组图片

显示一组 arrays

```python
def show_grid(arrays, n_cols=8, cmap='gray', show=False):
    arrays = np.array(arrays).transpose((0, 2, 3, 1))
    _, h, w, c = arrays.shape
    arrays = arrays.squeeze()
    if c > 1: cmap = None
    else: cmap = 'gray'
    num = arrays.shape[0]
    m, n = num // n_cols, n_cols
    fig, axes = plt.subplots(m, n)
    axes = axes.ravel()
    for i in range(num):
        axes[i].set_axis_off()
        axes[i].imshow(arrays[i], cmap=cmap)
    if show:
        plt.show()
```

同理, 只是这里每行显示 `n_cols` 张图片.



## 完整代码

参考了 <https://github.com/pytorch/vision/tree/master/torchvision/datasets>

```python
import os
from six.moves import urllib
from tqdm import tqdm
import gzip
import tarfile
import codecs
import numpy as np
import torch
import matplotlib
import matplotlib.pyplot as plt

## progress bar of download_url
def gen_bar_updater():
    pbar = tqdm(total=None)

    def bar_update(count, block_size, total_size):
        if pbar.total is None and total_size:
            pbar.total = total_size
        progress_bytes = count * block_size
        ## `count` is incremental,
        ## `pbar.n`: current state of the bar
        pbar.update(progress_bytes - pbar.n)

    return bar_update

def download_url(url, root, filename=None):
    if not os.path.exists(root):
        os.makedirs(root)

    if not filename:
        filename = os.path.basename(url)
    fpath = os.path.join(root, filename)

    if os.path.exists(fpath):
         print('{} exists, no need downloding!'.format(filename))
    else:
        print('Downloading {} to {}'.format(url, fpath))
        urllib.request.urlretrieve(url, fpath,
                               reporthook=gen_bar_updater())
    extract_gzip(fpath, remove_finished=False)


def extract_gzip(gzip_path, remove_finished=False):
    # ofile = gzip_path.replace('.gz', '')
    components = gzip_path.split('/')
    if 'mnist' in gzip_path:
        components[-1] = components[-1].split('.')[0]
    elif 'cifar' in gzip_path:
        components[-1] = 'cifar-10-batches-py'
    ofile = '/'.join(components)
    if os.path.exists(ofile):
        print('{} exist!'.format(ofile))
    else:
        print('Extracting {}'.format(gzip_path))
        if 'mnist' in gzip_path:
            with open(ofile, 'wb') as out_file, \
                    gzip.GzipFile(gzip_path) as in_file:
                out_file.write(in_file.read())
        elif 'cifar' in gzip_path:
            tar = tarfile.open(gzip_path, "r:gz")
            tar.extractall(os.path.dirname(gzip_path))
            tar.close()
        if remove_finished:
            os.remove(gzip_path)


def get_int(b):
    return int(codecs.encode(b, 'hex'), 16)

def read_image_file(path):
    with open(path, 'rb') as f:
        data = f.read()
        assert get_int(data[:4]) == 2051
        num_images = get_int(data[4 : 8])
        num_rows = get_int(data[8 : 12])
        num_cols = get_int(data[12 : 16])
        parsed = np.frombuffer(data, dtype=np.uint8, offset=16)
        return torch.from_numpy(parsed).view(num_images, 1, num_rows, num_cols)


def read_label_file(path):
    with open(path, 'rb') as f:
        data = f.read()
        assert get_int(data[:4]) == 2049
        num_images = get_int(data[4 : 8])
        parsed = np.frombuffer(data, dtype=np.uint8, offset=8)
        return torch.from_numpy(parsed).view(num_images).long()


def unpickle(datafile):
    import pickle
    with open(datafile, 'rb') as fo:
        data_dict = pickle.load(fo, encoding='bytes')
    return data_dict

def data_batch(i, path, key='data'):
    data_dict = unpickle(os.path.join(path, 'data_batch_{}'.format(i)))
    return data_dict[key]

def prepare_dataset(name, path, Train=True):
    training_file = name + '_train.pth'
    testing_file = name + '_test.pth'
    if name == 'mnist':
        if Train:
            data_file = training_file
            img_name = 'train-images-idx3-ubyte'
            label_name = 'train-labels-idx1-ubyte'
        else:
            data_file = testing_file
            img_name = 't10k-images-idx3-ubyte'
            label_name = 't10k-labels-idx1-ubyte'

        if os.path.exists(os.path.join(path, data_file)):
            return

        dataset = (
            read_image_file(os.path.join(path, img_name)),
            read_label_file(os.path.join(path, label_name))
        )

        with open(os.path.join(path, data_file), 'wb') as f:
            torch.save(dataset, f)
    elif name == 'cifar10':
        cifar_path = os.path.join(path, 'cifar-10-batches-py')
        if Train:
            data_file = training_file
            data_array = np.concatenate(
                [data_batch(i, cifar_path, b'data') for i in range(1, 6)],
                axis=0
            )
            label_array = np.concatenate(
                [data_batch(i, cifar_path, b'labels') for i in range(1, 6)],
                axis=0
            )
            torch_data = torch.from_numpy(data_array).view(-1, 3, 32, 32)
            torch_label= torch.from_numpy(label_array).long()
        else:
            data_file = testing_file
            data_dict = unpickle(os.path.join(cifar_path, 'test_batch'))
            data_array = data_dict[b'data']
            label_array = np.array(data_dict[b'labels'])
            torch_data = torch.from_numpy(data_array).view(-1, 3, 32, 32)
            torch_label= torch.from_numpy(label_array).long()

        if os.path.exists(os.path.join(path, data_file)):
            return

        dataset = (
            torch_data,
            torch_label,
        )

        with open(os.path.join(path, data_file), 'wb') as f:
            torch.save(dataset, f)


def show_array(array, show=False):
    array = np.array(array).transpose((1, 2, 0))
    h, w, c = array.shape
    array = array.squeeze()
    if c > 1: cmap = None
    else: cmap = 'gray'
    fig, ax = plt.subplots()
    ax.imshow(array, cmap=cmap)
    if show:
        plt.show()


def show_grid(arrays, n_cols=8, cmap='gray', show=False):
    arrays = np.array(arrays).transpose((0, 2, 3, 1))
    _, h, w, c = arrays.shape
    arrays = arrays.squeeze()
    if c > 1: cmap = None
    else: cmap = 'gray'
    num = arrays.shape[0]
    m, n = num // n_cols, n_cols
    fig, axes = plt.subplots(m, n)
    axes = axes.ravel()
    for i in range(num):
        axes[i].set_axis_off()
        axes[i].imshow(arrays[i], cmap=cmap)
    if show:
        plt.show()



if __name__ == '__main__':

    urls = [
            'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',
            'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',
            'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',
            'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',
        ]

    for url in urls:
        download_url(url, 'data', filename=None)
    prepare_dataset('mnist', 'data', Train=True)
    prepare_dataset('mnist', 'data', Train=False)

    # with open('data/mnist_test.pth', 'rb') as f:
        # test_set = torch.load(f)
        # test_images, test_labels = test_set
    # print(test_images[0].numpy().shape)
    # show_array(test_images[0].numpy(), show=False)
    # show_grid(test_images[:16].numpy(), show=True)
    urls = [
        'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',
    ]
    for url in urls:
        download_url(url, 'data', filename=None)

    prepare_dataset('cifar10', 'data', Train=True)
    prepare_dataset('cifar10', 'data', Train=False)

    with open('data/cifar10_test.pth', 'rb') as f:
        test_set = torch.load(f)
        test_images, test_labels = test_set
    print(test_images[0].numpy().shape)
    show_array(test_images[0].numpy(), show=False)
    show_grid(test_images[:16].numpy(), show=True)
```








## 参考资料
> - [pytorch torchvision:mnist.py](<https://github.com/pytorch/vision/blob/master/torchvision/datasets/utils.py>)
> - []()
